{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于Tree的ensemble的方法\n",
    "\n",
    "比如一共100个树，看每个feature一共在多少个树中出现了，出现得越多，则越重要。\n",
    "\n",
    "http://scikit-learn.org/stable/modules/ensemble.html#feature-importance 里面有这么一段：Individual decision trees intrinsically perform feature selection by selecting appropriate split points. This information can be used to measure the importance of each feature; the basic idea is: the more often a feature is used in the split points of a tree the more important that feature is. This notion of importance can be extended to decision tree ensembles by simply averaging the feature importance of each tree (see Feature importance evaluation for more details).\n",
    "\n",
    "也就是说，Tree天然就很适于判断feature的重要性。对于一棵树，我们看它作为split point的次数，对于一堆树，则可以继续平均。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
